================================================================================
LoRA FINE-TUNING FLOW DIAGRAM
================================================================================

┌─────────────────────────────────────────────────────────────────────────────┐
│                    BASE MODEL (IndicLegal-LLaMA-7B)                         │
│                    • 7B Parameters                                         │
│                    • Pre-trained on Legal Corpus                            │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                    ┌───────────────▼───────────────┐
                    │   LoRA CONFIGURATION          │
                    │   • Rank (r): 16             │
                    │   • Alpha: 32                 │
                    │   • Dropout: 0.05            │
                    │   • Target Modules:          │
                    │     - q_proj, v_proj         │
                    │     - k_proj, o_proj         │
                    │     - gate_proj, up_proj     │
                    │     - down_proj              │
                    └───────────────┬───────────────┘
                                    │
                    ┌───────────────▼───────────────┐
                    │   LoRA ADAPTERS               │
                    │   • Low-Rank Matrices         │
                    │   • Trainable Parameters:     │
                    │     ~8M (vs 7B full)         │
                    └───────────────┬───────────────┘
                                    │
                    ┌───────────────▼───────────────┐
                    │   TRAINING DATASET            │
                    │   • Legal QA Pairs            │
                    │   • IPC/CrPC/Constitution      │
                    │   • Hindi + English            │
                    │   • Format:                    │
                    │     Question → Answer         │
                    │     + Context                 │
                    └───────────────┬───────────────┘
                                    │
                    ┌───────────────▼───────────────┐
                    │   TRAINING LOOP               │
                    │   • Batch Size: 4             │
                    │   • Gradient Accumulation: 8  │
                    │   • Learning Rate: 2e-4        │
                    │   • Epochs: 3                  │
                    │   • Optimizer: AdamW           │
                    └───────────────┬───────────────┘
                                    │
                    ┌───────────────▼───────────────┐
                    │   LOSS COMPUTATION             │
                    │   • Language Modeling Loss     │
                    │   • Causal LM Objective       │
                    └───────────────┬───────────────┘
                                    │
                    ┌───────────────▼───────────────┐
                    │   BACKPROPAGATION              │
                    │   • Update LoRA Weights Only   │
                    │   • Base Model Frozen          │
                    └───────────────┬───────────────┘
                                    │
                    ┌───────────────▼───────────────┐
                    │   VALIDATION                   │
                    │   • Legal Accuracy             │
                    │   • Citation Accuracy          │
                    │   • Perplexity                 │
                    └───────────────┬───────────────┘
                                    │
                    ┌───────────────▼───────────────┐
                    │   FINE-TUNED MODEL             │
                    │   • Base Model (Frozen)        │
                    │   • LoRA Adapters (Trained)     │
                    │   • Legal Domain Adapted        │
                    └────────────────────────────────┘

================================================================================
TRAINING STAGES
================================================================================

Stage 1: Preparation
─────────────────────
• Load Base Model
• Initialize LoRA Adapters
• Prepare Training Dataset
• Set Training Hyperparameters

Stage 2: Training
─────────────────
For each epoch:
  For each batch:
    1. Forward Pass
       - Input: Question + Context
       - Output: Generated Answer
    2. Loss Computation
       - Compare with Ground Truth
       - Compute Language Modeling Loss
    3. Backward Pass
       - Compute Gradients
       - Update LoRA Weights Only
    4. Validation
       - Evaluate on Validation Set
       - Track Metrics

Stage 3: Saving
──────────────
• Save LoRA Adapters
• Save Tokenizer
• Save Training Config

================================================================================
LoRA MATHEMATICS
================================================================================

Original Weight Matrix: W (d × d)
LoRA Decomposition: W + ΔW
  where ΔW = BA
    B: (d × r) - Low-rank matrix
    A: (r × d) - Low-rank matrix
    r: Rank (typically 8-32)

Parameters:
  Original: d² parameters
  LoRA: 2rd parameters
  Reduction: (d² - 2rd) / d²

Example:
  d = 4096, r = 16
  Original: 16.7M parameters
  LoRA: 131K parameters
  Reduction: 99.2%

================================================================================
TRAINING CONFIGURATION
================================================================================

Model: IndicLegal-LLaMA-7B
LoRA Rank: 16
LoRA Alpha: 32
Target Modules: All attention + FFN
Batch Size: 4
Gradient Accumulation: 8
Effective Batch Size: 32
Learning Rate: 2e-4
Warmup Steps: 100
Max Grad Norm: 1.0
Epochs: 3
Optimizer: AdamW
LR Scheduler: Cosine

================================================================================

